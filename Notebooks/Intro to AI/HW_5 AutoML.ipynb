{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95-891 Homework 5 â€“ AutoML\n",
    "\n",
    "## Blaine Perry\n",
    "## Andrew ID: blainep\n",
    "Due Arpil 14th, 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import sin\n",
    "from math import pi\n",
    "from numpy import arange\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "\n",
    "from time import time\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('hw5.csv')\n",
    "\n",
    "# select relevant features\n",
    "# irrelevant features are ignored\n",
    "selected_features = ['#Followers',\n",
    "                     '#Friends',\n",
    "                     '#Retweets',\n",
    "                     '#Favorites',\n",
    "                     'Positive_sentiment',\n",
    "                     'Negative_sentiment',\n",
    "                     'Post_hour']\n",
    "\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# split the data into train and test\n",
    "train_df = selected_df.iloc[:80000]\n",
    "test_df = selected_df.iloc[80000:]\n",
    "\n",
    "\n",
    "X_train, y_train = train_df.loc[:, train_df.columns != '#Retweets'], train_df['#Retweets']\n",
    "X_test, y_test = test_df.loc[:, test_df.columns != '#Retweets'], test_df['#Retweets']\n",
    "\n",
    "# standardize the data\n",
    "scalar = StandardScaler().fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (80000, 6)\n",
      "y_train shape:  (80000,)\n",
      "X_test shape:  (20000, 6)\n",
      "y_test shape:  (20000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "print('X_test shape: ',X_test.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "# code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
    "def report(results, n_top=1):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the model and its hyperparameters\n",
    "clf = MLPRegressor(random_state=0)\n",
    "param_dist = {'hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,),\n",
    "                                     (60,), (70,), (80,), (90,), (100,)],\n",
    "              'learning_rate_init': [0.001, 0.01, 0.1]}\n",
    "\n",
    "n_iter_search = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 75.58 seconds for 20 candidates parameter settings.\n"
     ]
    }
   ],
   "source": [
    "# ###########################################################################\n",
    "# #Conduct randomsearch here with the predefined range.\n",
    "# 1-2 lines.\n",
    "random_search = RandomizedSearchCV(clf, param_dist, n_jobs=-1)\n",
    "##############################################################################\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest x_train R^2: 0.7854397246934642\n",
      "Highest x_test R^2: 0.6920379648057144\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.695 (std: 0.104)\n",
      "Parameters: {'learning_rate_init': 0.1, 'hidden_layer_sizes': (50,)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Print the highest R^2 on X_train.\n",
    "# Use the corresponding model to predict on X_test and get the R^2 score.\n",
    "\n",
    "clf_best = random_search.best_estimator_\n",
    "\n",
    "y_pred_train = clf_best.predict(X_train)\n",
    "y_pred_test = clf_best.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('Highest x_train R^2: ' + str(r2_train))\n",
    "print('Highest x_test R^2: ' + str(r2_test))\n",
    "report(random_search.cv_results_)\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 232.68 seconds for 33 candidate parameter settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Conduct GridSearch here with the predefined range.\n",
    "# 1-2 lines.\n",
    "grid_search = GridSearchCV(clf, param_dist, n_jobs=-1)\n",
    "##############################################################################\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest x_train R^2: 0.782634091221836\n",
      "Highest x_test R^2: 0.7993652664129686\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.704 (std: 0.182)\n",
      "Parameters: {'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Print the highest R^2 on X_train.\n",
    "# Use the corresponding model to predict on X_test and get the R^2 score.\n",
    "clf_best_grid = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = clf_best_grid.predict(X_train)\n",
    "y_pred_test = clf_best_grid.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('Highest x_train R^2: ' + str(r2_train))\n",
    "print('Highest x_test R^2: ' + str(r2_test))\n",
    "report(grid_search.cv_results_)\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# subset the data\n",
    "X_train_new, X_valid = X_train[:70000, :], X_train[70000:, :]\n",
    "y_train_new, y_valid = y_train[:70000], y_train[70000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# objective function\n",
    "# return the R^2 score on the validation set by parameters\n",
    "def objective(X_train, y_train, X_valid, y_valid, parameters):\n",
    "    clf = MLPRegressor(hidden_layer_sizes=parameters[0],\n",
    "                       learning_rate_init=parameters[1],\n",
    "                       random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_valid_predicted = clf.predict(X_valid)\n",
    "    return r2_score(y_valid, y_valid_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "##############################################################################\n",
    "# This function should return model's (Gaussian Process model) prediction value\n",
    "# on X. Here X is a hyperparameter combination, e.g., [20, 0.01].\n",
    "# The function returns both the predicted value and the uncertainty (std).\n",
    "    mu, std = model.predict(X, return_std=True)\n",
    "    return mu, std\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def acquisition_UCB(Xsamples, model):\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    ##############################################################################\n",
    "    return (mu + std) / 2\n",
    "    # you could simply return the average of the predicted value and the uncertainty.\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, model):\n",
    "    # random search, generate random samples\n",
    "    n_layers = np.random.randint(1, 100, 100)\n",
    "    learning_rates = np.random.uniform(0, 1, 100)\n",
    "    params = list(itertools.product(n_layers, learning_rates))\n",
    "    Xsamples = [list(ele) for ele in params]\n",
    "\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition_UCB(Xsamples, model)\n",
    "\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    return Xsamples[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create some initial points for GP\n",
    "params = [[10, 0.01],\n",
    "          [20, 0.1],\n",
    "          [50, 0.01],\n",
    "          [100, 0.001],\n",
    "          [100, 0.01]]\n",
    "y_params = [objective(X_train_new, y_train_new, X_valid, y_valid, param)\n",
    "            for param in params]\n",
    "\n",
    "##############################################################################\n",
    "# Here you should initialize a Gaussian Process model and fit with initial params\n",
    "# and the corresponding y_params\n",
    "\n",
    "model = GaussianProcessRegressor()\n",
    "model.fit(params, y_params)\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 0.5911551220358146] 0.5668907320268495\n",
      "[99, 0.004021887818007497] 0.5978890489888182\n",
      "[11, 0.613524039815785] 0.5399126492247341\n",
      "[49, 0.950877967788447] 0.48447557918176465\n",
      "[50, 0.9827423152362325] 0.4662777947753477\n",
      "[10, 0.9987479885922803] -0.19558086331453772\n",
      "[12, 0.006145513030104355] 0.5868439328771695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 0.0007637205740924635] 0.538070210397946\n",
      "[12, 0.979239620267569] 0.13294134593230655\n",
      "[21, 0.8998405888120525] 0.36472401981430447\n",
      "[19, 0.9967909515819313] 0.45948455782232767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 0.0003661726465133963] 0.5675292906388374\n",
      "[18, 0.04562035253902008] 0.5863834960935004\n",
      "[17, 0.8618714391479438] 0.13563651858695525\n",
      "[47, 0.9107867046841598] 0.31948473175119774\n",
      "[19, 0.020187172621119576] 0.5916845979746659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 0.0013416094431786263] 0.5984076903259485\n",
      "[14, 0.02117051425850025] 0.5921785287315473\n",
      "[13, 0.01241237258878225] 0.5946529334272366\n",
      "[52, 0.0029682218688358297] 0.5939627508577099\n",
      "[53, 0.891252891490782] 0.4349325103605509\n",
      "[49, 0.01023606482754058] 0.5951749967069391\n",
      "[15, 0.9881763226911041] 0.12098326245968583\n",
      "[54, 0.003423461313310616] 0.5954277714807257\n",
      "[55, 0.7867862240702225] 0.4912215652088586\n",
      "[56, 0.03735975451662732] 0.5424115068676219\n",
      "[57, 0.9599610790848776] 0.3274604804522211\n",
      "[7, 0.007218206661937954] 0.590246540410288\n",
      "[7, 0.9972091128840588] 0.36268726519735994\n",
      "[8, 0.0039683401781627214] 0.5971641414459141\n",
      "[5, 0.05833097577401403] 0.5893663692711514\n",
      "[5, 0.9963800741658632] 0.02837841103153238\n",
      "[4, 0.005305989023028701] 0.5897182575551014\n",
      "[55, 0.005003531701888164] 0.5948701696590124\n",
      "[2, 0.004554911091262603] -5.283656418253457e-05\n",
      "[97, 0.0012800370293796215] 0.5954188058690373\n",
      "[96, 0.6962397832636313] 0.3372855331117035\n",
      "[58, 0.0013822377683427867] 0.5976642948289332\n",
      "[59, 0.6950033595604941] 0.2863142440648333\n",
      "[22, 0.015865049288449007] 0.5940816516971934\n",
      "[23, 0.7294118093133146] 0.32257378174393825\n",
      "[98, 0.9543953047062818] 0.3768848011438358\n",
      "[98, 0.00541535585550279] 0.594413579956151\n",
      "[46, 0.019685612882907044] 0.5863596874272374\n",
      "[45, 0.702773599519992] 0.5191665572849795\n",
      "[45, 0.0014785000513312108] 0.5960078180737824\n",
      "[25, 0.001485928996137309] 0.5968032192903721\n",
      "[26, 0.6084250120327725] 0.45791383866190816\n",
      "[43, 0.23086912457215203] 0.5597650182299219\n",
      "[42, 0.9736570829709349] 0.2587050140493745\n",
      "Bayesian Optimization took 285.43 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#start a start time for the process\n",
    "start = time()\n",
    "\n",
    "# perform the optimization process\n",
    "for i in range(50):\n",
    "    # select the next point to sample\n",
    "    x = opt_acquisition(params, model)\n",
    "    # sample the point\n",
    "    actual = objective(X_train_new, y_train_new, X_valid, y_valid, x)\n",
    "    # summarize the finding\n",
    "    est, _ = surrogate(model, np.asarray(x).reshape(1, -1))\n",
    "\n",
    "    # add the data to the dataset\n",
    "    params.append(x)\n",
    "    y_params.append(actual)\n",
    "\n",
    "    #print(x, actual)\n",
    "\n",
    "    ##############################################################################\n",
    "    # # update the Gaussian Process model\n",
    "    # you need one line here to update the GP model with new observations.\n",
    "    model.fit(params, y_params)\n",
    "##############################################################################\n",
    "\n",
    "print(\"Bayesian Optimization took %.2f seconds.\"\n",
    "      % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R^2 for X_train:  0.5984076903259485\n",
      "Best R^2 for X_test 0.7994995400755596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# best result\n",
    "ix = argmax(y_params)\n",
    "print('Best R^2 for X_train: ', y_params[ix])\n",
    "\n",
    "clf = MLPRegressor(hidden_layer_sizes=params[ix][0],\n",
    "                   learning_rate_init=params[ix][1],\n",
    "                   random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "test_prediction = clf.predict(X_test)\n",
    "print('Best R^2 for X_test', r2_score(y_test, test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 8. Compare RandomSearch and GridSearch with Bayesian optimization, whatâ€™s your observation regarding both accuracy (train and test R^2 score) and the elapsed time?\n",
    "###### RandomSearch was the fastest of the three, with GridSearch and Bayesian optimization being far slower.  For accuracy, the Bayesian optimization produced a model which was slightly more accurate on the test data, but was worse on training data.  The RandomSearch found the worst model in terms of test and training accuracy.  This makes sense as it does not properly evaluate the test space, and only takes random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_2_Image_Classification_with_CNN_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
