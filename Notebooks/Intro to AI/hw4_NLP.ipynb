{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95-891 Homework 4 – Natural Language Processing\n",
    "\n",
    "## Blaine Perry\n",
    "## Andrew ID: blainep\n",
    "Due March 31st, 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\blain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\blain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the required packages\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from itertools import compress\n",
    "import collections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1: Data ETL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# first step is to preprocess the data, since this data contains odd formatting, I cant just read it in directly and need a helper function\n",
    "def read_data(name, categories, columns):\n",
    "    data = open(name, encoding = 'cp850' ).readlines()\n",
    "    data_array = []\n",
    "    for i, row in enumerate (data):\n",
    "        cols = row.split(sep=',')\n",
    "        if cols[2] in categories:\n",
    "            cols[5] = re.sub('_comma_' , '' , cols[5])  #because this is a csv, all commas are replaced by _comma_, we remove these here\n",
    "            data_array.append([cols[5], cols[2]])\n",
    "\n",
    "    return pd.DataFrame(data_array, columns = columns)\n",
    "\n",
    "columns = ['utterance', 'context']\n",
    "categories = ['sad', 'jealous', 'joyful', 'terrified']\n",
    "\n",
    "# Importing the datasets\n",
    "train = read_data(\"train.csv\", categories, columns)\n",
    "valid = read_data(\"valid.csv\", categories, columns)\n",
    "test = read_data(\"test.csv\", categories, columns)\n",
    "\n",
    "\n",
    "train_x = train.utterance\n",
    "train_y = train.context\n",
    "\n",
    "test_x = test.utterance\n",
    "test_y = test.context\n",
    "\n",
    "valid_x = valid.utterance\n",
    "valid_y = valid.context\n",
    "\n",
    "\n",
    "# Getting the train labels; this will be used for SGD classifier\n",
    "train_labels_unique = list(train['context'].unique())\n",
    "label_mapper = {}\n",
    "num = 0\n",
    "for label in train_labels_unique:\n",
    "    label_mapper[label] = num\n",
    "    num += 1\n",
    "\n",
    "\n",
    "train_labels = list(train['context'])\n",
    "train_labels_encoded = []\n",
    "for label in train_labels:\n",
    "    train_labels_encoded.append(label_mapper[label])\n",
    "\n",
    "# Getting test labels\n",
    "labels_test = list(test['context'])\n",
    "labels_encoded_test = []\n",
    "for label in labels_test:\n",
    "    labels_encoded_test.append(label_mapper[label])\n",
    "labels_encoded_test = np.array(labels_encoded_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2: Bag of Words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# use sklearn should be good\n",
    "train_count_vectorizer = CountVectorizer()\n",
    "X = train_count_vectorizer.fit_transform(train_x)\n",
    "encoding = X.toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(10686, 6832)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3: The shortcomings with the previous representation are ?\n",
    "###### There are many words such as 'a', 'the', etc. which are filler and do not contribute to the meaning of the sentence.  there are also many different variations on words which should be considered the same word, such as can't and cannot."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# remove stop words.\n",
    "# Getting the list of stopwords and appending additional words to it\n",
    "stopwords_list = list(set(stopwords.words('english')))\n",
    "stopwords_list.extend(['comma', '', '_comma_'])\n",
    "\n",
    "train_data_stop_removed = train_x.apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))  #here we use a lambda function to go through each word and see if it is a stop word, if it is, we do not add it back to the sentence\n",
    "test_data_stop_removed = test_x.apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\n",
    "\n",
    "\n",
    "# Creating the bag of words encoding again\n",
    "train_count_vectorizer = CountVectorizer()\n",
    "X_train = train_count_vectorizer.fit_transform(train_data_stop_removed)\n",
    "\n",
    "train_one_hot_encoding = X_train.toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Normalization\n",
    "# Normalizing the training data using tfidf transformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# A helper function to show results\n",
    "def show_results(train_test, label, preds, model_type = 'SGD'):\n",
    "    print(f'{train_test} accuracy :', np.mean(label == preds))\n",
    "\n",
    "    f1_score_vector = f1_score(label, preds, average=None)\n",
    "\n",
    "    print('F1 score :', np.mean(label == preds))\n",
    "\n",
    "    print('Confusion matrix :\\n', confusion_matrix(label, preds))\n",
    "\n",
    "    print(f'f1 score using {model_type} classifier is :', np.mean(f1_score_vector))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Normalization\n",
    "train_tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "train_embedding_tfidf_transformer = train_tfidf_transformer.fit_transform(X_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Building an SGD Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train = train_embedding_tfidf_transformer\n",
    "y_train = np.array(train_labels_encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.7730675650383679\n",
      "F1 score : 0.7730675650383679\n",
      "Confusion matrix :\n",
      " [[2154  166  237  151]\n",
      " [ 148 2026  203  178]\n",
      " [ 236  214 2188  245]\n",
      " [ 147  245  255 1893]]\n",
      "f1 score using SGD classifier is : 0.7730547599885254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = SGDClassifier(loss = 'log', max_iter = 500)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "train_predicted_labels = clf.predict(X_train)\n",
    "show_results('test', y_train, train_predicted_labels)\n",
    "\n",
    "misclassified = y_train != train_predicted_labels #find the misclassifications\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'terrified': 0, 'joyful': 1, 'sad': 2, 'jealous': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           utterance  true_label  \\\n0  I feel like getting prepared and then having a...           0   \n1         It's hard to stay clam. How do you do it?            0   \n2  Well pleased. You should be having brainsman!T...           1   \n3  During christmas a few years ago I did not get...           2   \n4  Since that day christmas has not been a good t...           2   \n\n   predicted_label  \n0                1  \n1                2  \n2                2  \n3                1  \n4                1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utterance</th>\n      <th>true_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I feel like getting prepared and then having a...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It's hard to stay clam. How do you do it?</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Well pleased. You should be having brainsman!T...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>During christmas a few years ago I did not get...</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Since that day christmas has not been a good t...</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = y_train[misclassified]\n",
    "utterances = train_x[misclassified]\n",
    "predictions = train_predicted_labels[misclassified]\n",
    "\n",
    "together = pd.DataFrame(zip(utterances, labels, predictions), columns=['utterance', 'true_label', 'predicted_label'])\n",
    "print(label_mapper)\n",
    "together.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Looking at the few misclassifications above, they seem reasonable.  For example, the first is \"I feel like getting prepared and then having a curve ball thrown at you throws you off.\", with truth label of terrified and prediction of joyful.  This could be that the classifier takes in curve ball and getting prepared and thinks that the user is going to a baseball game.  A joyful experience.\n",
    "###### Another misclassification was number 3 above, which states \"During christmas a few years ago I did not get any presents.\".  The truth classification was sad and the prediction was joyful, however the classifier most likely honed in on Christmas and assumes that everyone who talks about Christmas is happy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.6193921852387844\n",
      "F1 score : 0.6193921852387844\n",
      "Confusion matrix :\n",
      " [[211  27  31  29]\n",
      " [ 35 216  57  48]\n",
      " [ 51  45 237  41]\n",
      " [ 37  61  64 192]]\n",
      "f1 score using SGD classifier is : 0.6200081771190856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\blain\\anaconda3\\envs\\95891\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1632: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    }
   ],
   "source": [
    "# Using training data vocabulary on test data so that the features are consistent\n",
    "test_count_vectorizer = CountVectorizer(vocabulary = train_count_vectorizer.get_feature_names())\n",
    "X_test = test_count_vectorizer.fit_transform(test_data_stop_removed)\n",
    "\n",
    "test_one_hot_encoding = X_test.toarray()\n",
    "\n",
    "# Normalizing the test data\n",
    "test_tfidf_transformer = TfidfTransformer(smooth_idf=False,use_idf=True)\n",
    "test_embedding_tfidf_transformer = test_tfidf_transformer.fit_transform(test_one_hot_encoding)\n",
    "\n",
    "# Getting predictions on test data\n",
    "test_predicted_labels = clf.predict(test_embedding_tfidf_transformer)\n",
    "show_results('test', labels_encoded_test, test_predicted_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Classifier using pretrained embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Tokenizing the data\n",
    "train_tokens = [nltk.word_tokenize(sentences) for sentences in train_data_stop_removed]\n",
    "train_y = np.array(train_labels_encoded)\n",
    "\n",
    "test_tokens = [nltk.word_tokenize(sentences) for sentences in test_data_stop_removed]\n",
    "test_y = np.array(labels_encoded_test)\n",
    "\n",
    "# Loading the pretrained word2vec model from Google\n",
    "# download the model here: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#with some help from https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751\n",
    "\n",
    "# Create a list of strings, one for each title\n",
    "utterance_list = [utterance for utterance in train_data_stop_removed]\n",
    "\n",
    "# Collapse the list of strings into a single long string for processing\n",
    "utterance_string = ' '.join(utterance_list)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the string into words\n",
    "tokens = word_tokenize(utterance_string)\n",
    "\n",
    "# Remove non-alphabetic tokens, such as punctuation\n",
    "words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "# Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "vector_list = [model[word] for word in words if word in model.vocab]\n",
    "\n",
    "# Create a list of the words corresponding to these vectors\n",
    "words_filtered = [word for word in words if word in model.vocab]\n",
    "\n",
    "# Zip the words together with their vector representations\n",
    "word_vec_zip = zip(words_filtered, vector_list)\n",
    "\n",
    "# Cast to a dict so we can turn it into a DataFrame\n",
    "word_vec_dict = dict(word_vec_zip)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)\n",
    "\n",
    "# Our earlier preprocessing was done when we were dealing only with word vectors\n",
    "# Here, we need each document to remain a document\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stopwords_list]\n",
    "    doc = [word for word in doc if word.isalpha()]\n",
    "    return doc\n",
    "\n",
    "# Function that will help us drop documents that have no word vectors in word2vec\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)\n",
    "\n",
    "# Filter out documents\n",
    "def filter_docs(corpus, texts, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus and texts given the function condition_on_doc which takes a doc. The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    if texts is not None:\n",
    "        texts = [text for (text, doc) in zip(texts, corpus)\n",
    "                 if condition_on_doc(doc)]\n",
    "\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "def create_w2v_sets(data, labels, model):\n",
    "    # Preprocess the corpus\n",
    "    corpus = [preprocess(word) for word in data]\n",
    "\n",
    "    train_df = pd.DataFrame(zip(corpus, labels)) #create a training dataframe so that we drop the appropriate labels later on\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for _, doc in train_df.iterrows(): # append the vector for each document\n",
    "\n",
    "        if has_vector_representation(model, doc[0]):  #ensure that the document has vectors which exist in the model\n",
    "            x.append(document_vector(model, doc[0]))\n",
    "            y.append(doc[1])\n",
    "    x = np.array(x) # list to array\n",
    "    y = np.array(y) # list to array\n",
    "    return x,y\n",
    "\n",
    "train_X_w2v, train_Y_w2v =  create_w2v_sets(train_data_stop_removed, y_train, model)\n",
    "test_X_w2v, test_Y_w2v = create_w2v_sets(test_data_stop_removed, test_y, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP train accuracy : 0.6734482433832533\n",
      "F1 score : 0.6734482433832533\n",
      "Confusion matrix :\n",
      " [[1931  210  262  288]\n",
      " [ 190 1767  193  388]\n",
      " [ 320  387 1648  514]\n",
      " [ 153  315  247 1804]]\n",
      "f1 score using MLP classifier is : 0.6735349807788276\n",
      "MLP test accuracy : 0.6329941860465116\n",
      "F1 score : 0.6329941860465116\n",
      "Confusion matrix :\n",
      " [[222  28  24  24]\n",
      " [ 38 223  39  55]\n",
      " [ 47  44 216  65]\n",
      " [ 29  75  37 210]]\n",
      "f1 score using MLP classifier is : 0.6347848822004006\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(early_stopping = True).fit(train_X_w2v, train_Y_w2v)\n",
    "train_predict = MLP.predict(train_X_w2v)\n",
    "show_results('MLP train', train_Y_w2v, train_predict, model_type='MLP')\n",
    "\n",
    "test_predict = MLP.predict(test_X_w2v)\n",
    "show_results('MLP test', test_Y_w2v, test_predict, model_type='MLP')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Classifier using pretrained BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training embeddings. Please be patient, this takes forever.\n",
      "Completed training embeddings\n",
      "\n",
      "Started test embeddings. Please be patient, this takes forever.\n",
      "Completed test embeddings\n"
     ]
    }
   ],
   "source": [
    "# referenced a helpful guide to BERT: https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "# load the tokenizer and the model of distilbert-base-uncased\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "BERT_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# tokenize the text, then input the tokens (and masks) into the model to get the output.\n",
    "# Set up this helper function so that I can apply it to the dataframe\n",
    "def get_BERT_embeddings(data):\n",
    "\n",
    "    encoded_input = tokenizer(data, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = BERT_model(**encoded_input)\n",
    "    return output['last_hidden_state'][:,0,:][0].numpy()  #take the last hidden state of the bert model\n",
    "\n",
    "print('Started training embeddings. Please be patient, this takes forever.')\n",
    "x_train_BERT = train_data_stop_removed.apply(get_BERT_embeddings)\n",
    "print('Completed training embeddings\\n')\n",
    "\n",
    "print('Started test embeddings. Please be patient, this takes forever.')\n",
    "x_test_BERT = test_data_stop_removed.apply(get_BERT_embeddings)\n",
    "print('Completed test embeddings')\n",
    "\n",
    "#convert from pandas series to dataframe\n",
    "x_train_BERT = pd.DataFrame(dict(zip(x_train_BERT.index, x_train_BERT.values))).T\n",
    "x_test_BERT = pd.DataFrame(dict(zip(x_test_BERT.index, x_test_BERT.values))).T\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explain how you use the BERT output. Specifically, which token(s) output you use?\n",
    "###### from the output, we need to take the first position in the \"last_hidden_states\" dict.  This contains the tokens for classification.  It can be thought of as an embedding for the utterance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert_MLP train accuracy : 0.6991390604529291\n",
      "F1 score : 0.6991390604529291\n",
      "Confusion matrix :\n",
      " [[1931  220  291  266]\n",
      " [ 138 1878  222  317]\n",
      " [ 276  335 1760  512]\n",
      " [ 107  282  249 1902]]\n",
      "f1 score using MLP classifier is : 0.6998566393531345\n",
      "Bert_MLP test accuracy : 0.6157742402315485\n",
      "F1 score : 0.6157742402315485\n",
      "Confusion matrix :\n",
      " [[209  24  29  36]\n",
      " [ 27 220  38  71]\n",
      " [ 47  41 225  61]\n",
      " [ 30  77  50 197]]\n",
      "f1 score using MLP classifier is : 0.6183531717475763\n"
     ]
    }
   ],
   "source": [
    "# use the BERT output to train a MLP classifier\n",
    "Bert_MLP = MLPClassifier(early_stopping = True, max_iter=300).fit(x_train_BERT, train_y)\n",
    "train_predict = Bert_MLP.predict(x_train_BERT)\n",
    "show_results('Bert_MLP train', train_y, train_predict, model_type='MLP')\n",
    "\n",
    "test_predict = Bert_MLP.predict(x_test_BERT)\n",
    "show_results('Bert_MLP test', test_y, test_predict, model_type='MLP')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8: Read the paper and answer the following questions:\n",
    "#### 1) (0.5 points) What does this paper mean by \"fine-tuning\" results? How might you use such fine-tuning in building an empathetic chatbot?\n",
    "\n",
    "###### The paper means that the pre-trained models were further trained on the EmpatheticDialogues training data.  This was done to reduce training time by taking the knowledge gained in the pre-trained model and extending it to respond in a more empathetic way, by using the EmpatheticDialogues training set.  In this paper, the authors froze the Transformer encoder and classifiers.  We might use fine-tuning to build an empathetic chatbot in the same way.  If we were to freeze the encoder layers, we could train the decoder layers to more accurately respond with empathy.  This could be accomplished by adding an \"empathy score\" and maximizing it in the loss function.\n",
    "\n",
    "#### 2) (0.5 points) What properties of the transformer architecture make it well suited for this application?\n",
    "\n",
    "###### Transformers are based on the attention model which would allow the model to find the key phrases which indicate emotional state, and can then predict responses that are emotionally correct.\n",
    "\n",
    "#### 3) (0.5 points) Explain the metrics used to evaluate performance in Table 1 (P@1,100, AVG-BLEU, and PPL).\n",
    "\n",
    "###### P@1,100 is the precision retrieving the correct test candidate out of 100 test candidates.  It shows how often the model can select the correct response from 100 randomly selected samples.\n",
    "###### AVG-BLEU is the average of the BLEU 1-4 scores.  BLEU, or Bi-Lingual Evaluation Understudy, computes the similarity between the predicted text and human generated texts.  If given a number of human generated texts, it checks the predicted text to see how many of the words in the prediction are in the human generated texts.  In other words, it calculates precision of the words within the prediction.\n",
    "###### PPL is simply perplexity, or the reciprocal of probability of a sequence being in a corpus normalized by the sequence length.  It is used to evaluate the likelihood of a sequence of words.\n",
    "\n",
    "#### 4) (0.5 points) Which of the metrics do you think provides the best measure of performance of empathic systems and why?\n",
    "\n",
    "###### I believe BLEU would be the best metric in this case.  Assuming that humans are empathetic in their responses, we would want the similarity between the generated and human texts to be high.  When looking at PPL alone, we may find answers with low PPL which are not empathetic.\n",
    "\n",
    "#### 5) (0.5 points) Based on Tables 1 and 2, and your reading of the paper, what do you think would help the system get to human-level performance?\n",
    "\n",
    "###### Larger models with topics, and emotions prepended and then fine-tuned seemed to increase empathetic responses.  This indicates that giving the model some explicit understanding of the topic and emotion of an utterance's (à la the Elcor in Mass Effect) is helpful in increasing the model toward human level performance. It also shows that larger models may be needed to accurately predict empathetic responses.  In order to help the system reach human-level performance, I would try to use larger datasets with explicit topic and emotion labeling trained on large and complex models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_2_Image_Classification_with_CNN_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "95891",
   "language": "python",
   "display_name": "95891"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}