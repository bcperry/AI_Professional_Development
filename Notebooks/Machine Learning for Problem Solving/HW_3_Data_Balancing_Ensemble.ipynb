{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based (Ensemble) Models and Handling Imbalanced Data [30 points]\n",
    "\n",
    "For this problem, we will use the wine quality dataset on which the task is a binary classification of whether a given wine is of low or high quality based on different physicochemical features.\n",
    "Â \n",
    "The dataset consists of a set of physicochemical features as inputs and the target is wine quality stored in the target column, where a value of 1 corresponds to an instance of high quality wine and -1 corresponds to an instance of low quality ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (3pts)\n",
    "Load the data from library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate method of loading datsets bases on Piazza question @41 (load datasets error):\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Dataset:\n",
    "data = pd.read_csv('winequality-white.csv', ';')\n",
    "data['quality'] =data['quality'].replace([5, 6, 7, 8, 9, 10], [-1, -1, -1, -1, -1, -1])\n",
    "data['quality'] =data['quality'].replace([1, 2, 3, 4], [1, 1, 1, 1])\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Draw the class distribution of the dataset. What are possible problems if we train a classification model directly on this dataset?\n",
    "\n",
    "***The data is highly imbalainced.  Only about 4% of the wines are classified as high quality.  Directly training a classification model may lead to missclassifications due to data inbalance***\n",
    "\n",
    "***For this problem, there is a very high proportion of low quality wine and not very many high quality samples. If a model was trained on this data, it would be easy for the model to fit to the low quality data and still look very accurate. If 99% of the data is one type, guessing that type every time would be 99% accurate, but the high quality samples would never be correctly identified, leading to low recall.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of high quality observations: 0.03736218864842793%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries for plotting class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "count = data['quality'].value_counts()\n",
    "\n",
    "high_quality_ratio = count[1]/(count[1] + count[-1])\n",
    "print('Percentage of high quality observations: {}%'.format(high_quality_ratio))\n",
    "\n",
    "# color coding for 2 classes\n",
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "## code to plot the class distribution. Hint: countplot in seaborn\n",
    "sns.countplot(x = 'quality', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing a Random Forest classfier directly on the data (3pts)\n",
    "\n",
    "Let's first train a random forest classifier with default parameters using X_train and y_train and test the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.950204081632653\n",
      "Random forest classifier recall: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # class for random forest classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Instantiate and fit a random forest classifier to the training data\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predict = rf.predict(X_test)\n",
    "\n",
    "## Measure and print out the accuracy and recall\n",
    "test_acc = accuracy_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quetion:** Compute the recall and accuracy scores of the random forest classifier. How is the gap between the accuracy and recall scores? Provide an explanation.\n",
    "\n",
    "***The accuracy is very high (95%), likely following the tendency described above, but the recall is very low (14%). There is a large gap between the recall and accuracy score of the random forest.  This is likely because of the imbalance in the data.  Since only 3.7% of the data are high quality wines, we would be able to make a classifier highly accurate by classifying all wines as low quality, this would however have poor recall as we see here.***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data balancing via Smote (6pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of high quality counts in the balanced data: 50.0%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE #Over sampling\n",
    "import numpy as np\n",
    "\n",
    "## Instantiate smote and balance training data only\n",
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "count_SMOTE = y_train.value_counts()\n",
    "high_quality_ratio_SMOTE = count_SMOTE[1]/(count_SMOTE[1] + count_SMOTE[-1])\n",
    "\n",
    "## Compute and print percentage of high quality wine after balancing\n",
    "print('Percentage of high quality counts in the balanced data: {}%'.format(high_quality_ratio_SMOTE*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Plot the distribution of balanced training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bcper\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "## plot the class distribution of training data after balanced\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain and test our random forest model on the balanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.9428571428571428\n",
      "Random forest classifier recall: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "## Instantiate random forest and train on balanced training data\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predict = rf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the new random forest classifier. How do the accuracy and recall change compared to those without data balancing?\n",
    "\n",
    "***The accuracy went down slightly, from 95% to 94%, but the recall nearly tripled from 12% to 36%.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control complexity of the model (18pts)\n",
    "\n",
    "#### Control the depth of decision trees in our ensemble (6pts)\n",
    "By default, the decision trees in random forest are expanded until all leaves are pure or until all leaves contain less than a certain number set by min_samples_split parameter. Let's try a fixed maximum depth that the tree can expand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.8375510204081633\n",
      "Random forest classifier recall: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with max depth trees being 3\n",
    "rf = RandomForestClassifier(max_depth = 3)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predict = rf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the new random forest classifier. How do the accuracy and recall change compared to those in the default parameter case?\n",
    "\n",
    "***Again, accuracy decreased this time from 94% to 84%, but there was another increase in recall from 34% to 61%.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the number of trees in the forest (6pts)\n",
    "By default, we use 10 random trees. Let's increase this number to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.830204081632653\n",
      "Random forest classifier recall: 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with max depth of 3 and 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 3)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predict = rf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the random forest classifier. How do the accuracy and recall change compared to those with 10 trees? What do the results imply about increasing the number of trees?\n",
    "\n",
    "***This time the accuracy and recall show only a small change. This shows that increasing the number of trees from 10 to 100 does not have much of an effect for this particular model.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree pruning by min_impurity_decrease (6pts)\n",
    "By default, the tree keeps expanding until the impurity is 0. However, we can specify a minimum impurity decrease amount under which nodes in the tree stop branching. RandomForestClassifier in sklearn use min_impurity_decrease for setting this threshold. Let's try that on our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuray: 0.913469387755102\n",
      "Random forest classifier recall: 0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model with min impurity decrease of 0.001\n",
    "rf = RandomForestClassifier(min_impurity_decrease = 0.001)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predict = rf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier accuray:', test_acc)\n",
    "\n",
    "test_recall = recall_score(y_test, rf_test_predict)\n",
    "\n",
    "print('Random forest classifier recall:', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the recall and accuracy scores of the random forest classifier. How does the recall change compared to those with 10 trees and max_depth = 3?\n",
    "\n",
    "***In this case, comparing to the 10 tree depth 3 model, both the accuracy and recall are higher. The accuracy increased from 82% to 91% while the recall increased slightly from 50% to 51%.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
