{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Credit Card Fraud Detection (10 pts)\n",
    "\n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (1 pts)\n",
    "Load the data from `fraud_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of fraud observations 1.64%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('fraud_data.csv')\n",
    "\n",
    "## Print the percentage of fraud observations\n",
    "print(\"Percentage of fraud observations {:.2%}\".format(data['Class'].sum() / data.shape[0]))\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)  # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "***1.64% of the observations from the dataset are fraud***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the majority class label (4pts)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? (Here accuracy is the ratio of the number of correctly classified transactions to the total number of transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuray: 0.9852507374631269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "## Instantiate and fit a dummy classifier that always predict class label by the majority class of the training data\n",
    "## Use DummyClassifier in sklearn with strategy 'most_frequent\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "dummy_test_pred = dummy.predict(X_test)\n",
    "\n",
    "## Measure test accuracy of your dummy classifier\n",
    "dummy_test_acc = accuracy_score(y_test, dummy_test_pred)\n",
    "\n",
    "print('Dummy classifier accuray:', dummy_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the accuracy of the dummy classifier look (very low, low, high, very high)? Give an explanation.*\n",
    "\n",
    "***The dummy classifier is very accurate (98.5%) however, this is misleading because the classes of data are very unbalanced.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How many fraudulent transactions are correctly classified? (This is the **recall** score/measure)*\n",
    "\n",
    "***None of the fraudulent transactions are correctly classified, because the dummy classifier classified all samples as 'non-fraudulent'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## Measure test recall score of your dummy classifier\n",
    "dummy_test_recall = recall_score(y_test, dummy_test_pred)\n",
    "\n",
    "print('Dummy classifier recall:', dummy_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *How does the recall of the dummy classifier look (very low, low, high, very high)? Give an explanation.*\n",
    "\n",
    "***The recall for the dummy classifier is 0.  Since the dummy classifier always returns the majority class, it never predicts the minority class, in this case the negative class***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a logistic regression model (3pts)\n",
    "\n",
    "Train a logisitic regression classifier with default parameters using X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9964970501474927\n",
      "Logistic classifier recall: 0.7875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "## Instantiate a logistic regression model and fit to the training data\n",
    "logR = LogisticRegression(max_iter = 1000)\n",
    "logR.fit(X_train, y_train)\n",
    "\n",
    "logR_test_pred = logR.predict(X_test)\n",
    "\n",
    "## Measure test accuracy \n",
    "logR_test_acc = accuracy_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results of logistic regression with those of the above dummy classifier*\n",
    "\n",
    "***The logistic regression works considerably better than the dummy classifier.  Since it actually predicts positives, we see that the recall is much better.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for selecting hyperparameters for Logistic Regression (2pts)\n",
    "\n",
    "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic classifier accuray: 0.9964970501474927\n",
      "Logistic classifier recall: 0.7875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Define the grid of logistic regression parameters\n",
    "parameters = {'penalty': ['l1', 'l2'],\n",
    "              'C':[0.01, 0.1, 1, 10, 100]}\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "    \n",
    "## Perform grid search CV to find best model parameter setting\n",
    "cmodel = GridSearchCV(model, param_grid=parameters, cv=3, scoring='recall', n_jobs=-2, \n",
    "                    return_train_score=True)\n",
    "cmodel.fit(X_train, y_train.ravel())\n",
    "\n",
    "## Fit logistic regression with best parameters to the entire training data\n",
    "model = cmodel.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "logR_test_pred = model.predict(X_test)\n",
    "\n",
    "## Measure test accuracy\n",
    "logR_test_acc = accuracy_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier accuray:', logR_test_acc)\n",
    "\n",
    "## Measure test recall\n",
    "logR_test_recall = recall_score(y_test, logR_test_pred)\n",
    "\n",
    "print('Logistic classifier recall:', logR_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** *Compare the results with that of logistic regression with default parameters*\n",
    "\n",
    "***The default matches the regression using the gridsearch.***"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
